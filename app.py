import streamlit as st
import whisper
import aiohttp
import asyncio
import json
from pathlib import Path
import tempfile
from pydub import AudioSegment
import time
from audio_recorder_streamlit import audio_recorder
import os

class OllamaService:
    def __init__(self):
        """
        Inicializa o servi√ßo usando a API da OpenAI.
        """
        api_key = os.getenv('OPENAI_API_KEY') or st.secrets.get("OPENAI_API_KEY")
        if not api_key:
            st.error("‚ö†Ô∏è Chave da API da OpenAI n√£o encontrada! Por favor, configure a vari√°vel OPENAI_API_KEY")
            st.stop()
            
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        self.base_url = "https://api.openai.com/v1/chat/completions"
    
    async def get_response(self, transcript: str) -> str:
        """
        Envia o texto transcrito para o modelo e recebe a an√°lise.
        """
        messages = [
            {"role": "system", "content": """Voc√™ √© Carl Gustav Jung, o renomado psiquiatra e psicoterapeuta su√≠√ßo. 
            Mantenha um tom pessoal, acolhedor e s√°bio em suas respostas, como se estivesse conversando diretamente com seu paciente.
            Evite listagens formais ou an√°lises muito t√©cnicas. Em vez disso, integre naturalmente os conceitos em sua fala.
            Use ocasionalmente express√µes como "minha teoria", "em minha experi√™ncia", "como descobri em meus estudos".
            Mantenha o tom amig√°vel mas profundo, caracter√≠stico de uma conversa terap√™utica."""},
            {"role": "user", "content": transcript}
        ]
        
        payload = {
            "model": "gpt-4o-mini-2024-07-18",
            "messages": messages,
            "temperature": 0.9,
            "max_tokens": 500,
            "top_p": 0.95,
            "frequency_penalty": 0.7,
            "presence_penalty": 0.7
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(self.base_url, headers=self.headers, json=payload) as response:
                    if response.status == 200:
                        data = await response.json()
                        return data['choices'][0]['message']['content'].strip()
                    else:
                        error_text = await response.text()
                        raise Exception(f"Erro na API da OpenAI: {error_text}")
        except Exception as e:
            raise Exception(f"Falha na comunica√ß√£o com a API: {str(e)}")

class AudioProcessor:
    """
    Classe respons√°vel pelo processamento do √°udio e transcri√ß√£o.
    Separamos esta l√≥gica para melhor organiza√ß√£o do c√≥digo.
    """
    def __init__(self):
        self.model = whisper.load_model("base")
    
    def process_audio_chunk(self, chunk_path: str) -> str:
        """Processa um chunk de √°udio e retorna a transcri√ß√£o"""
        return self.model.transcribe(str(chunk_path))['text']
    
    def split_audio(self, audio_file, chunk_duration=30000):
        """Divide o √°udio em chunks menores para processamento mais eficiente"""
        audio = AudioSegment.from_file(audio_file)
        chunks = []
        for i in range(0, len(audio), chunk_duration):
            chunks.append(audio[i:i + chunk_duration])
        return chunks

def initialize_session_state():
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'audio_processor' not in st.session_state:
        st.session_state.audio_processor = AudioProcessor()
    if 'ollama_service' not in st.session_state:
        st.session_state.ollama_service = OllamaService()
    if 'text_input' not in st.session_state:
        st.session_state.text_input = ""

def clear_text():
    st.session_state.text_input = ""

def process_text():
    if st.session_state.text_input.strip():
        text = st.session_state.text_input
        # Add user message
        st.session_state.messages.append({
            "is_user": True,
            "content": f"üí¨ *Mensagem:*\n\n{text}"
        })
        
        # Process text
        asyncio.run(process_text_input(text))
        
        # Clear input
        clear_text()
        
        # Rerun to update chat
        st.rerun()

def display_message(is_user: bool, content: str):
    with st.chat_message("user" if is_user else "assistant"):
        st.markdown(content)

async def process_text_input(text: str):
    try:
        response = await st.session_state.ollama_service.get_response(text)
        st.session_state.messages.append({
            "is_user": False,
            "content": response
        })
    except Exception as e:
        st.error(f"Erro na an√°lise: {str(e)}")

def main():
    st.set_page_config(
        page_title="Chat Junguiano",
        page_icon="üß†",
        layout="wide"
    )
    
    st.title("üí≠ Consult√≥rio do Dr. Jung")
    st.markdown("""
    ### üéôÔ∏è Converse com Dr. Carl Gustav Jung
    Compartilhe seus pensamentos, sonhos e reflex√µes em um di√°logo terap√™utico.
    """)
    
    initialize_session_state()
    
    # Display chat history
    for message in st.session_state.messages:
        display_message(message["is_user"], message["content"])
    
    # Criar duas colunas para √°udio e texto
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üé§ Grava√ß√£o de √Åudio")
        # Bot√£o de grava√ß√£o de √°udio
        audio_bytes = audio_recorder()
        if audio_bytes:
            with st.spinner("üéß Processando seu √°udio..."):
                try:
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
                        tmp_file.write(audio_bytes)
                        tmp_path = Path(tmp_file.name)
                    
                    # Process audio
                    chunks = st.session_state.audio_processor.split_audio(tmp_path)
                    transcripts = []
                    
                    progress_text = st.empty()
                    for i, chunk in enumerate(chunks):
                        progress_text.text(f"üìù Transcrevendo parte {i+1} de {len(chunks)}...")
                        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as chunk_file:
                            chunk.export(chunk_file.name, format='wav')
                            transcript = st.session_state.audio_processor.process_audio_chunk(chunk_file.name)
                            transcripts.append(transcript)
                    
                    full_transcript = " ".join(transcripts)
                    
                    # Add user message
                    st.session_state.messages.append({
                        "is_user": True,
                        "content": f"üé§ *√Åudio transcrito:*\n\n{full_transcript}"
                    })
                    
                    # Get analysis
                    progress_text.text("ü§î Analisando...")
                    async def get_analysis():
                        try:
                            response = await st.session_state.ollama_service.get_response(full_transcript)
                            st.session_state.messages.append({
                                "is_user": False,
                                "content": response
                            })
                        except Exception as e:
                            st.error(f"Erro na an√°lise: {str(e)}")
                    
                    asyncio.run(get_analysis())
                    progress_text.empty()
                    
                    # Rerun to update chat
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"Erro no processamento: {str(e)}")
    
    with col2:
        st.markdown("#### üí¨ Mensagem de Texto")
        # Input de texto
        st.text_area(
            "Digite sua mensagem",
            key="text_input",
            height=100,
            on_change=process_text
        )
        st.button("Enviar Mensagem", on_click=process_text)
    
    # Upload de arquivo de √°udio (opcional)
    st.markdown("#### üìÅ Ou fa√ßa upload de um arquivo de √°udio")
    audio_file = st.file_uploader(
        "Envie um arquivo de √°udio",
        type=['wav', 'mp3', 'm4a'],
        label_visibility="collapsed"
    )
    
    if audio_file:
        with st.spinner("üéß Ouvindo seu √°udio..."):
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=Path(audio_file.name).suffix) as tmp_file:
                    tmp_file.write(audio_file.getvalue())
                    tmp_path = Path(tmp_file.name)
                
                # Process audio
                chunks = st.session_state.audio_processor.split_audio(tmp_path)
                transcripts = []
                
                progress_text = st.empty()
                for i, chunk in enumerate(chunks):
                    progress_text.text(f"üìù Transcrevendo parte {i+1} de {len(chunks)}...")
                    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as chunk_file:
                        chunk.export(chunk_file.name, format='wav')
                        transcript = st.session_state.audio_processor.process_audio_chunk(chunk_file.name)
                        transcripts.append(transcript)
                
                full_transcript = " ".join(transcripts)
                
                # Add user message
                st.session_state.messages.append({
                    "is_user": True,
                    "content": f"üé§ *√Åudio transcrito:*\n\n{full_transcript}"
                })
                
                # Get analysis
                progress_text.text("ü§î Analisando...")
                async def get_analysis():
                    try:
                        response = await st.session_state.ollama_service.get_response(full_transcript)
                        st.session_state.messages.append({
                            "is_user": False,
                            "content": response
                        })
                    except Exception as e:
                        st.error(f"Erro na an√°lise: {str(e)}")
                
                asyncio.run(get_analysis())
                progress_text.empty()
                
                # Rerun to update chat
                st.rerun()
                
            except Exception as e:
                st.error(f"Erro no processamento: {str(e)}")
    
    # Adiciona um pouco de espa√ßo e informa√ß√µes √∫teis no final
    st.markdown("---")
    st.markdown("""
    üí° **Notas do Dr. Jung:**
    - Sinta-se √† vontade para compartilhar seus sonhos e experi√™ncias
    - Podemos conversar atrav√©s de mensagens de voz ou texto
    - Estou aqui para explorar os mist√©rios da sua psique
    - Como sempre digo, "Quem olha para fora, sonha; quem olha para dentro, desperta"
    """)

if __name__ == "__main__":
    main()